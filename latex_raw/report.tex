\PassOptionsToPackage{quiet}{fontspec} 
\documentclass{ctexart}
\usepackage{anyfontsize}
\usepackage{lipsum}
\usepackage{xcolor,listings}
\usepackage{graphicx,float}
\usepackage{verbatim}
\usepackage{algorithm,algorithmic,amsmath}
\usepackage{tikz}
\usepackage[colorlinks,linkcolor=blue,anchorcolor=blue,citecolor=green]{hyperref}
\usetikzlibrary{positioning, shapes.geometric}
\graphicspath{{imgs/}}
% \ctexset{section={format+=\raggedright}}
\lstset{
    showstringspaces=false,
    frame=single,
    numbers=left,
    numberstyle=\color{darkgray},
    backgroundcolor=\color{white},
    keywordstyle=\color{blue},
    commentstyle=\it\color[RGB]{0,100,0},
    stringstyle=\sl\color{red},
}
\begin{document}
\title{数字图像处理基础-图书ISBN号字符识别}
\author{覃梓鑫(软工2003-20202005175)}
\date{\today}
\maketitle
\tableofcontents
\newpage
\section{概述}

\textbf{题目:}图书ISBN号字符识别

\textbf{设计目的:}通过实现对ISBN号的字符识别，以学习掌握数字图像处理的基本知识与技能。

\textbf{内容概述:}
要实现对ISBN号的识别，首先需要预处理图片，将其自动旋转使字符水平分布，裁切出图片中条形码矩形区域，然后对图片进行灰度化二值化，并分割出数字行所在区域，进一步将每个字符切割出来。接着对分割出的字符逐个与标准模板匹配，识别出每个字符。最后进行优化调整，并在窗口化程序中输出结果。

\textbf{运行环境:}Windows10 + Python 3.10.6

所需 Python 主要第三方库如下：
\begin{itemize}
    \item numpy==1.23.4
    \item cv==1.0.0
    \item matplotlib==3.6.2
    \item Pillow==9.3.0
\end{itemize}

\textit{如果想要查看所有依赖库，请在项目根目录下输入 pip freeze。其中 Pillow 库是为了用 ImageTk 在窗口化显示内容，与核心逻辑无关。}

\textbf{开发工具:}%不用加多余的\\
\begin{description}
    \item[操作系统] Windows 10 21H2
    \item[集成开发环境] Visual Studio Code 1.73.1
    \item[文档编写工具] TeXworks 0.6.6
    \item[编程语言] Python 3.10.6
    \item[版本管理工具] git 2.29.0
    \item[编码格式] UTF8
\end{description}

\section{整体设计}

程序执行的流程图如下：

\begin{tikzpicture}[node distance=10pt]
    \node[draw, rounded corners] (start) {开始};
    \node[draw, below=of start] (input) {打开图片};
    \node[draw, below=of input] (rotate){自动旋转图片至字符水平};
    \node[draw, below=of rotate] (resize){缩放过大的图片};
    \node[draw, below=of resize, text width=140pt] (cut) {裁切图片的条形码矩形区域, \linebreak 并得到正反两张子图};
    \node[draw, below=of cut] (split) {对子图分别分割每个字符};
    \node[draw, below=of split] (match) {为每个字符进行模板匹配识别字符};
    \node[draw, below=of match] (compare) {优化调整比较正反子图、历史最优解结果};
    \node[draw, diamond, aspect=3, below=of compare] (choice) {是否到达最大二值化阈值};%宽高比3
    \node[draw, right=30pt of choice,text width=55pt] (getThr){选取下一个二值化阈值};
    \node[draw, rounded corners, below=25pt of choice] (end) {输出答案};
    \draw[->] (start)--(input);
    \draw[->] (input)--(rotate);
    \draw[->] (rotate)--(resize);
    \draw[->] (resize)--(cut);
    \draw[->] (cut)--(split);
    \draw[->] (split)--(match);
    \draw[->] (match)--(compare);
    \draw[->] (compare)--(choice);
    \draw[->] (choice)--node[above]{是}(end);
    \draw[->] (choice)--node[left]{否}(getThr);
    \draw[->] (getThr)--(getThr|-cut)->(cut);
\end{tikzpicture}

下面扼要地阐述一下每个步骤的功能与实现原理，它们将在“具体实现”一节中被详细描述。

\begin{description}
    \item[打开图片] 通过窗口化程序让用户在资源管理器中选择一张图片打开。支持多种格式。
    \item[自动旋转] 基于Hough算法直线检测探测条形码中的条形直线的斜率，以此为基准将条形码旋转至垂直。\textbf{算法改进:}采用倍增的思路快速枚举直线长度阈值参数。
    \item[缩放图片] 过大的图片不会增加识别准确率。为了提高运行速度，将过大的图片等比缩小。
    \item[裁切图片] 先进行高斯模糊平滑处理，然后用Canny算法做边缘检测，然后求出轮廓上的所有矩形，筛除不合理矩形后取出最大的矩形区域作为条形码所在区域。\textbf{算法改进:}为了提高准确率，先在彩色图像上处理一次，再二值化后处理第二次，共裁切两次。
    \item[分割字符] 基于行列特征，找出条形码所在行区间，往上一个区间为ISBN号所在区间，对该区间按列特征分割出每个字符，并作初步筛除。
    \item[模板匹配] 事先准备多套字体的每个字符模板。将待匹配字符缩放和归一化，然后求相关系数，将系数最大的结果作为识别字符值。
    \item[优化调整] 枚举二值化阈值，对不同二值化阈值下不同正反旋转的图片的若干结果找出最符合的一个输出。基于ISBN校验码、统计规律等多因素进行筛选与调整结果。 
    \item[输出结果] 将识别结果输出到窗口化程序上。 
\end{description}


\section{具体实现}
\textit{为了表述的方便，该节按照模块进行分节，并在每个模块内部分别描述其具体必要的程序框图、数学模型、核心程序与处理过程图片。}
\subsection{灰度化}
根据课件(第11章-P38页-4彩色平衡)内容可知，彩色图像数字化后，景物颜色会偏移真实颜色，导致三基色不平衡。这里采用白平衡法计算灰度，即使用公式：%不需要\\
\[I(x,y)=0.299\cdot f_R(x,y)+0.587\cdot f_G(x,y)+0.114\cdot f_B(x,y)\] %不需要\\

但是如果直接使用Python迭代来处理上述过程，非常缓慢。所以考虑用\textbf{矩阵运算优化}。我们知道，向量内积的计算结果是实数，故有：
\[(R,G,B)\cdot(0.299,0.587,0.114)=0.299R+0.587G+0.114B\]

因此，考虑用向量内积，直接调用底层依托 C++ 实现的 numpy 的向量运算 dot 函数，一来 C++ 比 Python 快，二来矩阵运算比迭代快，这样能起到不小的常数优化作用。在下文的其他具体实现里也会反复用到类似的思路。因此，核心代码如下：
\begin{lstlisting}[language=python]
import numpy as np
def toGrey(img):
    if len(img.shape) == 2:  # 已经是灰度图像了
        return img
    rd = img.shape[2]  # 可能是3/4(png有alpha通道)
    line = [0.299, 0.587, 0.114, 0][:rd]
    trans = np.array(line).transpose()  # 矩阵转置
    img2 = np.dot(img, trans).astype(img.dtype)
    img2 = np.reshape(img2, img.shape[:2])
    return img2
\end{lstlisting}
运行效果如下：
\begin{figure}[htbp]
    \centering
    \includegraphics[height=120pt]{sample_toGrey}
    \caption{灰度化效果展示}
\end{figure}


\subsection{二值化}
根据课件(第9章-3基于阈值的图像分割)内容可知，可以按照图像的灰度不同，选取一个阈值 $x$，将灰度 $\ge x$ 的都转为一种灰度，其余的转为另一种灰度，实现二值化。

这个阈值如果手动选取的话适应性不够强，但是如果使用自适应阈值，即通过某种算法计算直接得到阈值 $x$，如 Otsu 算法，在实践验证中，发现效果也不是很理想。\textit{(Otsu 算法见下文算法比较)}

考虑采用一种比较朴素的思路，即枚举阈值。因为阈值的取值范围是 $[0,255]$。不妨以 $10$ 为公差，等差地枚举这个范围内的若干个阈值，然后以该阈值进行二值化。枚举次数约为 $25$ 次。显然，这么做的代价是，本来只需要对原图进行 $1$ 次识别 ISBN，会变成需要对原图进行至多 $25$ 次识别。不过，考虑到计算机算力较高，也能在相对可以接受的时间内求出结果。

为了提高效率，下面代码使用了矩阵运算加速。

二值化核心代码如下：
\begin{lstlisting}[language=python]
def toBinary(img, x, ltx=0, gex=255):
    '''传入灰度图img和阈值x,将其二值化并返回\n
    规定<x的染成白色(ltx),>=x的染成黑色(gex)'''
    img2 = img.copy()
    img2[img2 < x] = ltx
    img2[img2 >= x] = gex
    return img2
\end{lstlisting}

任取阈值(这里取的是 Otsu 算法求的阈值)，运行效果如下：
\begin{figure}[htbp]
    \centering
    \includegraphics[height=120pt]{sample_toBinary}
    \caption{二值化效果展示}
\end{figure}

\begin{comment}
所以考虑用基本自适应阈值。采用 Otsu 算法(最大类间方差法)，具体步骤如下：
设图像长宽为 $n,m$，最佳阈值是 $x$，$< x$ 的点有 $n_0$ 个，$\ge x$ 的点有 $n_1$ 个，原图 $< x$ 的点平均灰度为 $\mu_0$，$\ge x$ 的点平均灰度为 $\mu_1$，令：
\[w_0=\frac{n_0}{nm},\quad w_1=\frac{n_1}{nm}\]
显然满足：
\[n_0+n_1=nm,\quad w_0+w_1=1\]
则二值化前的均值 $\mu$ 显然满足：
\[\mu=w_0\cdot\mu_0+w_1\cdot\mu_1\]
为了让方差最大化，设方差 $\sigma$ 为：
\[\sigma=w_0\cdot(\mu_0-\mu)^2+w_1\cdot(\mu_1-\mu)^2\]

联立解得：$\sigma=w_0\cdot w_1\cdot (\mu_0-\mu_1)^2$，因此，将所有 $\ge x$ 的点与 $< x$ 的点分别染色为两种灰度，即可实现灰度化。

具体到代码实现上，可以枚举 $x\in[0,255]$，然后分别计算 $\sigma$，将取得最大 $\sigma$ 的 $x$ 作为阈值即可。

考虑到在本题中，一般是从按的背景上分割出暗的物体(即数字)，所以将 $< x$ 的都染为黑色，$\ge x$ 的都染成白色。

上述代码涉及大量遍历图像的操作，将其用\textbf{矩阵运算优化}，能显著提升运算效率。时间复杂度为 $O(255nm)$，对较小的图像能以几乎一瞬间求出结果。

核心代码如下：
\begin{lstlisting}[language=python]
import numpy as np
def getThrestHold(img):
    n, m = img.shape
    mx, x = -1, 0  # mx是当前最大值,x是取得最值的阈值
    np.seterr(divide='ignore',invalid='ignore')#零除
    for i in range(0, 256):
        n0 = np.sum(img < i)
        n1 = n*m-n0
        w0 = n0/(n*m)
        w1 = 1-w0
        mu0 = np.sum(img[img < i])/n0
        mu1 = np.sum(img[img >= i])/n1
        g = w0*w1*(mu0-mu1)**2
        if g > mx:
            mx, x = g, i
    return x
def toBinary(img, x, ltx=0, gex=255):
    img2 = img.copy()
    img2[img2 < x] = ltx
    img2[img2 >= x] = gex
    return img2
\end{lstlisting}
运行效果如下：
\begin{figure}[htbp]
    \centering
    \includegraphics[height=120pt]{sample_toBinary}
    \caption{二值化效果展示}
\end{figure}
\end{comment}


\subsection{字符定位及分割}
基本原理：将图片二值化之后(假设背景是白色，其余是黑色)，在理想情况下(没有旋转、没有多余内容、噪声等)，如果统计每一行每一列有多少个黑点，绘制水平和垂直统计图。核心代码如下：
\begin{lstlisting}[language=python]
def getHoriAndVertSum(img):
    img1 = ((255-img)//255).astype(np.uint16)
    sumVert = img1.sum(axis=0)
    sumHori = img1.sum(axis=1)
    return [sumHori, sumVert]
\end{lstlisting}
可以发现ISBN的部分会呈现出一段特殊波的形状，如图所示：\textit{(作图代码见附录)}
\begin{figure}[H]%让插入的图片紧跟在文字后面
    \centering
    \includegraphics[height=260pt]{isbn_sum}
    \caption{ISBN图的统计特征}
\end{figure}

观察图像可知，垂直统计图的条形码处的波形波动也跟条形码一样剧烈变化，且水平统计图的条形码处是一段平的较高的图形。而ISBN号一定出现在其条形码的上下两端出现。根据ISBN号的知识可知，上下出现的数字通常是相同的\textit{(如果不同，一般一个是旧版ISBN，一个是新版ISBN，二者指向同一本书)}。则任取一边进行识别即可。

\textit{注：初始版本的实现采用的是有所不同的思路，后来实践效果很差故进行了改进优化，初始算法见下文算法比较。}

根据实践和调试经验，我们发现下面行与条形码距离太近，而且受到首尾条形码的干扰，较难识别。上面行间距大，干扰相对少。所以我们优先考虑识别上面的行，如果无法识别再考虑识别下面的行。

找到上述的每个波形，可以设置一个阈值 $low$，然后对离散函数 $f$(即每行/列下标为自变量，该行/列的黑点数为因变量的函数) 进行切割。作一条 $y=low$ 直线截断函数 $f$，所有函数值都 $\ge low$ 的区间值组成一个个波形，将这些区间记录下来即可。我们可以采用遍历的方法实现该操作，获取每个区间。

这个阈值 $low$ 的选取需要根据不同图像而做改变。不妨设 $f$ 的均值为 $\overline{f}$，设置 $low=0.32\overline{f}$。 

显然，数字行区间出现在条形码区间的上下。且条形码区间的长度是最长的。我们不妨先找到长度最长的区间，然后取其相邻的区间即可。

核心代码如下：
\begin{lstlisting}[language=python]
def getRanges(sums, low=0.32):
    '''输入向量,返回所有值>=low*均值的连续峰段'''
    lim = low*sums.mean()
    ans = []  # 所有函数值>=lim的区间端点[l,r]
    inLow = True  # 当前是否扫描到<lim的下标
    left, right = -1, -1  # 临时变量
    n = sums.shape[0]  # 总长
    for i in range(n):
        # 进入符合条件的区间
        if sums[i] >= lim and inLow:
            left, inLow = i, False
        # 退出符合条件的区间
        if sums[i] < lim and not inLow:
            right, inLow = i, True
            ans.append([left, right])
    return ans
def getNumberLineRange(sums, low=0.35):
    '''输入向量,返回一个数字行的下标范围[l,r]'''
    low = sums.mean()*low
    rng = getRanges(sums)
    if len(rng) == 0:  # 图片有误
        return [0, 0]
    # 找到最长的段对应的下标
    strip = max(rng, key=lambda x: x[1]-x[0])
    sid = rng.index(strip)
    if sid > 0:  # 上一段
        return rng[sid-1]
    if sid+1 < len(rng):  # 下一段
        return rng[sid+1]
    return [0, 0]  # 只有条形码
\end{lstlisting}

分割效果如下：
\begin{figure}[H]
    \centering
    \includegraphics[height=120pt]{sample_splitRow2}
    \caption{按行分割效果}
\end{figure}

将其按行分割后，再次求其列特征，调用上述函数，得到统计图如下：
\begin{figure}[H]
    \centering
    \includegraphics[height=120pt]{sample_splitRow_ana2}
    \caption{按行分割后的按行统计图}
\end{figure}

可以发现，每个字符都对应一段连续的波。按照类似上面的办法将其分割即可。直接调整上述代码\textit{(见附录)}，得到效果如下：
\begin{figure}[H]
    \centering
    \includegraphics[height=80pt]{sample_splitNum2}
    \caption{分割后得到的每个字符}
\end{figure}

可以发现，分割出来的内容里含有无关的元素，包括 ISBN 四个字符和短横线 -。对复杂的图像，可能还有一些噪声、误点等。考虑如何初步筛除这些内容。

关于图像去噪，可以用滤波器等方法先做预处理。对短横线，不难发现其统计特征是，该字符只有少数行有黑点，大部分行没有黑点，不妨直接将大部分行基本是空白的字符给去除，这样可以把短横线和一些误点去除。还可能有一些大面积污点，其特征是几乎整个区域都是黑点，我们可以把这样的也去除。对 ISBN 四个字符，考虑在后续模板匹配时去除。

核心代码如下：
\begin{lstlisting}[language=python]
def filtRanges(img, arr):
    '''输入区间,返回经过初步筛选后的有效区间'''
    res = []
    h = img.shape[0]
    for l, r in arr:
        sub = img[:, l:r+1]
        blacks = sub[sub == 0].size
        lens = r-l+1
        tot = h*lens
        if blacks >= tot*0.7:  # 黑色太多
            continue
        sumH, sumV = getHoriAndVertSum(sub)
        vrows = sumH[sumH > 0.05*h].size
        if vrows < 0.28*h:  # 空白行太多
            continue
        res.append([l, r])
    return res
\end{lstlisting}

效果如下，去除横线的效果显著：
\begin{figure}[H]
    \centering
    \includegraphics[height=70pt]{sample_splitNum_flit2}
    \caption{分割后得到的每个字符(经初步筛查)}
\end{figure}

将本节代码全部整合为一个函数，如下所示：
\begin{lstlisting}[language=python]
def splitNumbers(img):
    '''输入一张二值化图像
    返回其分割出来的字符子图列表'''
    sumHori, sumVert = getHoriAndVertSum(img)
    l, r = getNumberLineRange(sumHori)
    img2 = img[l:r, :]
    sumH2, sumVert2 = getHoriAndVertSum(img2)
    rng = filtRanges(
        img2, getRanges(sumVert2, 0.12))
    imgs = splitByVerts(img2, rng)
    return imgs
\end{lstlisting}

\subsection{预处理旋转}
上述字符定位与分割过程对理想状态的 ISBN 字符分割表现良好，但是并非所有图像都是理想的。最常见的就是存在旋转，如：

\begin{figure}[H]
    \centering
    \includegraphics[height=260pt]{isbn_rotated}
    \caption{旋转过的ISBN图像及其分析}
\end{figure}

观察可知，ISBN 条形码明显的特征是有许多直线的条形，被旋转后，直线的朝向也会发生改变。如果我们能找出这些条形码直线及其旋转角，就能将其旋转回去。

根据课件(第9章-基于边缘检测的图像分割-Hough变换)可知，使用 Hough(霍夫)变换能够找到图中的直线。我们可以先使用 Canny 算子进行边缘检测，然后使用 Hough 变换对边缘检测结果提取其中的直线。

在实践过程中，不难发现，使用 Hough 变换需要设定一个阈值 $lim$，只有直线上的点数(即直线长度)超过 $lim$ 的直线才能被检测到。然而，图像变化多样，我们很难实现设定固定的 $lim$ 来满足不同的真实情境。因此，我采用了\textbf{倍增法}来快速枚举 $lim$ 的值，具体思想为：先设定一个较高的初始 $lim$，然后进行 Hough 变换找直线，如果找到的直线数目没有或很少，就证明阈值过高，这时将阈值除以一个常数来缩小阈值 $lim$，并继续查找，一直重复如上步骤直到找到为止。可以证明当阈值趋于 $0$ 时必然能找到。该算法能在对数复杂度内找到一个较为合适的阈值并进行直线分割。

核心代码如下：

\begin{lstlisting}[language=python]
def getLines(img):
    #传入二值化图像,输出其倍增法所有检测出来的直线
    #50,150是最小最大阈值,3是sobel卷积核大小
    edges = cv2.Canny(img, 50, 150, apertureSize=3)
    lim = int(np.min(img.shape)*0.8)
    while True:
        lines=cv2.HoughLines(edges,1,np.pi/180,lim)
        if type(lines) == type(None) 
            or len(lines) <= 5:
            lim = int(lim*0.9)
            continue#找不到/太少就不断缩小要求
        return lines
\end{lstlisting}

效果如图所示：

\begin{figure}[H]
    \centering
    \includegraphics[height=120pt]{hough}
    \caption{Hough变换处理旋转图像提取直线并标注}
\end{figure}

进行上述过程后，实际上我们将得到一组直线。由于检测出来的直线不保证都是条形码上的直线，所以我们考虑选择这些直线里斜率处于中位数的作为图像的倾斜角，并对图像进行旋转还原。

Hough 变换得到的每条直线都是极坐标系下的 $(\rho,\theta)$ 参数，通过极坐标变换，可以计算出该直线在平面直角坐标下的任意两点，从而计算出直线的斜率。然后将直线斜率旋转到与纵坐标轴垂直即可。

代码如下：
\begin{lstlisting}[language=python]
def getMidAngle(lines):
    '''给定极坐标直线组,返回位于中位数斜角(角度制)'''
    lt = []
    for line in lines:
        rho, theta = line[0]
        a = np.cos(theta)
        b = np.sin(theta)
        x0 = a * rho
        y0 = b * rho
        x1 = int(x0 + 1000 * (-b))
        y1 = int(y0 + 1000 * (a))
        x2 = int(x0 - 1000 * (-b))
        y2 = int(y0 - 1000 * (a))
        k = np.arctan2(x2-x1, y2-y1)
        lt.append(k/np.pi*180)
    lt.sort()
    return lt[lines.shape[0]//2]
\end{lstlisting}

旋转时会产生新的图像区域，如果图片(书封面)本身是深色背景的，则图片边缘都是黑色的，应当用黑色填充；否则，应当用白色填充，可以进行特判，取出现频率最高的颜色进行填充。

进行旋转的核心代码如下：
\begin{lstlisting}[language=python]
def rotateImg(img, ang):
    #以中心旋转图像,顺时针转动ang角度并返回(白色填充)
    h, w = img.shape
    cx, cy = w//2, h//2
    # 1.0表示不缩放
    m = cv2.getRotationMatrix2D((cx, cy), -ang, 1.0)
    mc, ms = np.abs(m[0, 0:2])
    nw = int(h*ms+w*mc)
    nh = int(h*mc+w*ms)
    m[0, 2] += (nw/2)-cx
    m[1, 2] += (nh/2)-cy
    #分类讨论填充新区域的颜色
    numBlack = img[img == 0].size
    numWhite = img.size-numBlack
    if numBlack > numWhite:
        c = (0, 0, 0)
    else:
        c = (255, 255, 255)
    return cv2.warpAffine(img, m, (nw, nh),
            borderValue=c)
\end{lstlisting}

合并代码如下：
\begin{lstlisting}[language=python]
def autoRotate(img):
    '''以二值化图像为输入，输出自动旋转后的图像'''
    lines = getLines(img)
    ang = getMidAngle(lines)
    return rotateImg(img, ang)
\end{lstlisting}

效果图展示：
\begin{figure}[H]
    \centering
    \includegraphics[height=120pt]{sample_autoRotate}
    \caption{将条形码自动旋转到垂直效果}
\end{figure}

显然，根据算法步骤可知，我们可以将条形码从“打横”的变成“打竖”的，但是旋转到大致垂直后，条形码上的字究竟是正的，还是反的，这是 Hough 变换无法实现的。为了解决这个问题，我们将在后续处理中，将图片分别当成是正的和反的都处理一遍，哪个匹配出更多内容就取哪个。

\subsection{预处理图片分割}
进行过预处理旋转后，仍有一个问题，如果图像不只有条形码，还有书本封面的其他内容，会干扰条形码的分析。所以我们希望能先预处理，使其只截取出条形码部分(如图3所示效果)。否则，其统计特征如下，进行分析困难：
\begin{figure}[H]
    \centering
    \includegraphics[height=120pt]{isbn_beforeCut}
    \caption{条形码外的封面内容干扰统计}
\end{figure}

检测一张图像中出现的矩形区域，可以采用 Suzuki, S. and Abe, K. 在论文(\textit{见参考文献})中提出的算法。调用相关算法后，我们能够得到图像上的所有轮廓。根据本题的特殊性，我们只需要选取其中的所有矩形轮廓。特别地，有时候如果轮廓检测失败，可能会得到许多很小的轮廓，不妨设置一个阈值如 $20\%$，所有面积小于原图像的 $20\%$ 的矩形全部忽略掉。然后，我们取出最大的矩形，作为检测的目标。

为了得到更准确的结果，我们需要实现进行预处理，例如可以先进行高斯模糊，然后再用 Canny 算法做边缘检测，以边缘检测结果的二值化图像开始提取轮廓。

核心代码如下：

\begin{lstlisting}[language=python]
def getMainRectangle(img):
    '''传入任意图像,返回其出现的最大矩形区域'''
    imgGray = toGrey(img)
    # 高斯模糊
    imgBlur = cv2.GaussianBlur(imgGray, (5, 5), 1)
    # Canny算子边缘检测
    imgCanny = cv2.Canny(imgBlur, 60, 60)
    # 边缘检测,RETR_TREE可能更精准
    contours, _ = cv2.findContours(
    imgCanny, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)
    res = []  # 答案
    nh, nw = img.shape[:2]
    totArea = nh*nw
    for obj in contours:
        # 计算轮廓内区域的面积
        area = cv2.contourArea(obj)
        if area <= 0.2*totArea:  # 矩形太小
            continue
        # 计算轮廓周长
        perimeter = cv2.arcLength(obj, True)
        # 获取轮廓角点坐标
        approx = cv2.approxPolyDP(
            obj, 0.02*perimeter, True)
        CornerNum = len(approx)  # 轮廓角点的数量
        # 获取坐标值和宽度、高度
        x, y, w, h = cv2.boundingRect(approx)
        if CornerNum == 4:  # 是矩形
            res.append([x, y, w, h])
    if len(res) == 0:  # 找不到
        return [0, 0, nw, nh]
    # 取出最大的矩形
    ans = max(res, key=lambda x: x[2]*x[3])  
    return ans
\end{lstlisting}

效果如图所示：

\begin{figure}[H]
    \centering
    \includegraphics[height=120pt]{sample_graphSplit}
    \caption{截取图片中的矩形}
\end{figure}

然而，根据实践经验，直接进行矩形探测会有如下问题：如果书籍封面太花，即图案等干扰因素较多(如本节第一张图片)。为了达到更好的效果，我们可以进行两次分割。第一次分割直接调用上述做法，对第一次分割后的图像，再进行灰度化、二值化后进行第二次分割，以期望达到更好的效果。

如图所示(中图为第一次分割(找不到矩形)，右图为第二次分割)：

\begin{figure}[H]
    \centering
    \includegraphics[height=120pt]{sample_graphSplit2}
    \caption{两次探测截取图片中的矩形}
\end{figure}


\subsection{字符识别}

因为上文我们已经分割出了每个字符，所以我们只需要对每个字符分别与每个标准字符进行比较，看其与哪个字符相似度最高，就认为它是哪个字符。

为了提高准确率，识别出不同的字体，我们考虑准备多套标准字符。经过对条形码的相关知识研究，我们发现 ISBN 条形码上主流的常见字体有两套，我们只截取与 ISBN 码相关的字符，如下图所示：

\begin{figure}[H]
    \centering
    \includegraphics[height=120pt]{standard_fonts2}
    \caption{条形码字体的字符模板}
\end{figure}

接下来，对要识别的图片中分割出的每个字符，分别与每个标准模板进行比较，哪个相似度最高就认为该字符是哪个字符。在识别之前需要将待检测字符的图片长宽调整到与要比较的模板一致，进行大小归一化。

因为需要进行缩放，且上文分割出来的字符子图都是边缘几乎没有空白的。因此，如果模板的边缘较多空白，会在模板匹配时将字符子图拉长或压扁，从而使得匹配效果很差。因此，处理标准模板时，应当尽可能少留多余的空白区域，且保持正确的比例。

模板匹配是一种最原始、最基本的模式识别方法，研究某一特定对象物的图案位于图像的什么地方，进而识别对象物，这就是一个匹配问题。

模板匹配的主要原理为用如下公式计算相似性。设 $T(m,n)$ 是模板，$S(m,n)$ 是被搜索图。当两张图大小调整到相同时，相似性 $D$ 为：
\[D=\sum_{i=1}^m\sum_{j=1}^n(S(i,j)-T(i,j))^2\]

将其归一化，即相关系数 $R$ 为：

\[
R=\frac
{\sum_{i=1}^m\sum_{j=1}^nS(i,j)T(i,j)}
{\sqrt{\sum_{i=1}^m\sum_{j=1}^nS(i,j)^2}
\sqrt{\sum_{i=1}^m\sum_{j=1}^nS(i,j)^2}}
\]

使用如下公式，$R$的取值归一化到了 $[-1,1]$，且计算值越接近 $1$，表示越相关，越接近 $-1$ 表示越不相关。

根据公式可知，我们只需要对每个被搜索图，对每个模板都计算一次 $R$，计算得最大的那个字符就认为是结果。代码如下：

\begin{lstlisting}[language=python]
def compare(target, std):
    '''比较target与模板图像std的相似性并返回'''
    # 将target的大小缩放到与std一致
    target = cv2.resize(target, std.shape[::-1])
    res = cv2.matchTemplate(
        target, std, cv2.TM_CCOEFF_NORMED)
    # 返回值分别是min_val,max_val,min_loc,max_loc
    return cv2.minMaxLoc(res)[1]  # 只要maxval
def getNumber(src):
    '''将一张图片与全体模板比较
    取最大相似的字符作结果'''
    maxv, maxchar = 0, '?'
    for fi in range(2):  # fi是第几套字体
        for i in strname:  # i是字符值
            v = compare(src, tems[fi][i])
            if v > maxv:
                maxv, maxchar = v, i
    return maxchar
def getMatch(img):
    '''给定二值化图像，输出识别结果数组'''
    srcs = splitNumbers(img)
    return [getNumber(i) for i in srcs]
\end{lstlisting}

其中，上面代码的 tems 变量是一个列表，其元素是一个字典，字典元素是经过灰度化、二值化的从外部读入的模板图片。即相当于是一个模板的二维数组。

\subsection{ISBN号识别的优化调整}

下面展示优化匹配，提高准确率的修正算法过程。并在本节末提供整合本章全部小节的整合代码函数接口。

首先，匹配过程中会遇到 ISBN 四个字符，还可能会遇到未被初筛筛掉的短横线，我们需要在匹配结果中将其删掉。

经过实践表明，数字 0 与字符 B 具有较高的相似性，在匹配时可能会将 0 匹配为 B。然而我们知道，条形码行中只会出现最多一个 B，所以对匹配到的其他的 B，我们统统特判其视为 0。

因此，初步筛选的代码如下：
\begin{lstlisting}[language=python]
def filtRes(m):
    '''输入匹配结果，对结果进行筛除和修正'''
    r = []
    hasB = False  # 是否出现过B
    for i in m:
        # 首次出现B
        if i == 'B' and not hasB:
            hasB = True
            continue
        # 再次出现B,根据实践经验,结果应修改为0
        if i == 'B' and hasB:
            i = '0'
        # 只保留数字
        if i not in 'ISBN-':
            r.append(i)
    return r
\end{lstlisting}

之后，我们得到经过筛选的结果。由于在上文中，一来我们进行过旋转后无法判别正反，故对每张图片，我们将其分为原图和旋转 180 度后的图，分别需要进行判定。我们需要比较这两次识别，哪次是更优的，哪个就是正面作为结果，为此，我们首先需要判定怎样的结果是合理的。

根据相关知识，可知 ISBN 号有两种版本。不妨设第 $i$ 位 ISBN 号数字为 $m_i$。ISBN 号的最后一位是校验码 $s$，可以通过前面的数字位计算得知，如果计算结果与校验码一致，说明无误。

旧版 ISBN 号有十位，校验码计算公式为：
\[s=\sum_{i=1}^9m_i\cdot(11-i)\bmod{11}\]

如果 $s\le 9$，则校验码就是 $s$；否则 $s=10$，校验码为 X。

新版 ISBN 号有十三位，校验码计算公式为：
\[s=(10-(\sum_{i=1}^6m_{2i-1}+\sum_{i=1}^63m_{2i})\bmod 10)\bmod{10}\]

即奇数位权重 $1$，偶数位 $3$。$s$ 就是校验码。

特别地，在某些时候，有小概率 AI 会把大量的噪声或错误图像认定为数字，且存在全零序列满足上面的校验码规则，即无效 ISBN 码 $00\cdots 0$ 也被认为是正确的。

这时，根据统计规律，ISBN 码中每个数字出现的频率应该近似大致相等\textit{(事实上严格来说不是，因为 ISBN 码每一段有严格的格式编码要求)}，所以不妨近似地认为 ISBN 码的平均数应该接近 $\frac{1}{10}\sum_{i=0}^9i=4.5$。如果我们比较的两方都满足校验码规则，则取更接近 $4.5$ 的一个作为合法 ISBN 码。

因为这个判断的代码冗长，故不列出具体实现，可在项目中具体查看。这里只给出伪代码。
\begin{algorithm}
    \caption{比较两个ISBN序列哪个更合法(betterMatch)}
    \label{betterMatch}
    \renewcommand{\algorithmicrequire}{\textbf{输入:}}
    \renewcommand{\algorithmicensure}{\textbf{输出:}}
    \begin{algorithmic}
        \REQUIRE ISBN号序列 $m_1,m_2$
        \ENSURE 更佳的序列 $m$
        \STATE 对 $m_1,m_2$ 进行初筛分别得到序列 $d_1,d_2$
        \STATE 求 $d_1,d_2$ 的 ISBN 校验码是否合法
        \IF{二者都合法}
        \STATE 求 $d_1,d_2$ 的平均数
        \RETURN 平均数较与 $4.5$ 更接近的一方
        \ELSE
            \IF{其中一个合法}
            \RETURN 合法的一方
            \ELSE
                \IF{有一方长度为 $13$ 或 $10$}
                \RETURN 优先任选长为 $13$ 的，其次选 $10$ 的
                \ELSE
                \RETURN 任选一个
                \ENDIF
            \ENDIF
        \ENDIF
    \end{algorithmic}
\end{algorithm}

经由上述算法，我们可以对一张设定了特定二值化阈值的图片进行比较，从而解决了上文的正反面问题：

\begin{lstlisting}[language=python]
def matchFlip(img):
    '''输出一张图片,将其正反都匹配一次取最优'''
    img1 = img.copy()
    img2 = rotateImg(img1, 180)
    res1 = getMatch(img1)
    res2 = getMatch(img2)
    return betterMatch(res1, res2)
\end{lstlisting}

最后，我们采取枚举二值化阈值的办法，调用上述算法，对多个结果分别比较，每次将计算出来的新结果与历史最优结果比较，然后取最优的结果作为 ISBN 号识别结果。

特别地，在一些时候，考虑到拍摄不全等原因，最右边界的数字经常会残缺。如果我们匹配出了正常长度，但是不满足校验码规则的结果，我们不妨用 ISBN 号校验码算法求出最后一位的值。即：

\begin{lstlisting}[language=python]
def adjudgeByChecksum(m):
    if len(m) not in (10, 13):
        return m  # 长度不对无解
    if m[:-1].count('X'):
        return m  # 非末位有X无解
    if not checkISBN(m): # 不合法就校正
        m[-1] = getChecksum(m)
    return m 
\end{lstlisting}

此外，手机拍摄的图片的像素值很大。而做识别无需用到这么大的像素，因为模板本身像素较低，比较时也会将图像缩放。所以，如果图片本身大小过大，不妨先等比例缩放一下，让其保持比较适合的尺寸，以提高计算速度。

调整尺寸的代码如下：

\begin{lstlisting}[language=python]
def reshape(img, mw=1000, mh=1000):
    '''给定图片,等比例裁剪使长宽不超mw,mh'''
    h, w = img.shape[:2]
    sh, sw = mh/h, mw/w
    s = min(sw, sh, 1)  # 与1比较,防止放大
    res = cv2.resize(img, (0, 0), fx=s, fy=s)
    return res
\end{lstlisting}

因此，对图片的预处理，包括自动旋转与旋转后自动调节大小，即：

\begin{lstlisting}[language=python]
def autoRotateC(img):
    '''以彩色图像为输入，输出自动旋转后的图像'''
    img2 = toGrey(img)
    img2 = toBinary(img2, getThrestHold(img2))
    lines = getLines(img2)
    ang = getMidAngle(lines)
    return rotateImg(img, ang)
def preDeal(img0):
    '''给定一张图片,将其裁剪大小和自动旋转'''
    img = autoRotateC(img0)
    img = reshape(img)
    return img
\end{lstlisting}

之后，根据上文描述，我们两次识别裁剪的方法将旋转后的图像裁切，使其只包含条形码部分：

\begin{lstlisting}[language=python]
def autoCut(img0, thr):
    '''传入彩色图像，两次匹配找到最大矩形区域子图\n
    返回结果是二值化后的子图'''
    img = cutImage(img0)
    img = toGrey(img)
    img = toBinary(img, thr)
    img = cutImage(img)
    return img
\end{lstlisting}

之后，进行字符匹配并做优化处理，得到最终结果并返回。本章的所有内容可以凝练为下面的函数接口：

\begin{lstlisting}[language=python]
def iterMatch(img0):
    '''给定一张图片,枚举二值化阈值取最好结果\n
    输出其ISBN字符串结果(以列表形式)'''
    img = preDeal(img0)
    ans = []  # 当前最优结果
    for thr in range(5, 255, 10):
        img1 = autoCut(img, thr)
        res = matchFlip(img1)
        print(thr, res)
        ans = betterMatch(ans, res)
    return adjudgeByChecksum(ans)
\end{lstlisting}

在窗口化程序中调用上述接口，效果如下：
\begin{figure}[H]
    \centering
    \includegraphics[height=120pt]{sample_stdout}
    \caption{识别ISBN号的最终结果}
\end{figure}

可以发现，准确地识别了所有的 ISBN 数字，且运行速度可以接受(在本机运行大约 1s 能出结果)。

\section{实验结果及分析}
\subsection{实验结果}

下图是所有的测试用例：

\begin{figure}[H]
    \centering
    \includegraphics[height=120pt]{test_raw}
    \caption{测试用例}
\end{figure}

可以看到，这些数据具有一定的挑战性。因为除了最基本的情况(如第 $1$ 个样例)外，其他样例含有噪声(图片的阴影、照片的污点等)、模糊(拍摄不清、像素较低等)、不完整(如只有上半部分/下半部分)、不同角度的旋转，识别难度较高。

下面是这些用例的输出结果\textit{(对原图人眼难观察的，附上了便于人眼观察的结果，但该结果不会作为输入放到程序，程序处理的是原图)}：

\begin{figure}[H]
    \centering
    \includegraphics[height=150pt]{test_01}\quad
    \includegraphics[height=150pt]{test_02}\\
    \includegraphics[height=150pt]{test_03}\quad
    \includegraphics[height=150pt]{test_04}\\
    \includegraphics[height=150pt]{test_05}\quad
    \includegraphics[height=150pt]{test_06}
    \caption{测试结果}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[height=150pt]{test_07}\quad
    \includegraphics[height=150pt]{test_08}\\
    \includegraphics[height=150pt]{test_09}\quad
    \includegraphics[height=150pt]{test_10}\\
    \includegraphics[height=150pt]{test_11}\quad
    \includegraphics[height=150pt]{test_12}
    \caption{测试结果}
\end{figure}

可以看到，上述的 $12$ 个测试用例都准确地得到了正确结果。用例中包含了各种不同的角度旋转、包含背景干扰(如第 $3,6$ 个样例)、包含不完整的条形码(如第 $9,10$ 个样例)，可以说明该程序可以在较为复杂的情况下能够准确地得到识别结果，健壮性良好。

此外，上述图片中的格式支持多样，包括 jpg, png, tif。而且支持不同大小尺寸的图片，无论是中小图片还是相机拍摄的分辨率很高的图像，都能识别。执行速度可以接受，通常而言运算的最长用时不会超过 $5$ 秒，平均能在 $0.5\sim2$ 秒内得到结果。

综上所述，我们可以认为该程序取得了可观的成果，能够应用在实践中解决生产生活问题。

\subsection{不同算法比较}

\subsubsection{二值化}
在初版设计中，我采用了采用 Otsu 算法(最大类间方差法)，具体步骤如下：

设图像长宽为 $n,m$，最佳阈值是 $x$，$< x$ 的点有 $n_0$ 个，$\ge x$ 的点有 $n_1$ 个，原图 $< x$ 的点平均灰度为 $\mu_0$，$\ge x$ 的点平均灰度为 $\mu_1$，令：
\[w_0=\frac{n_0}{nm},\quad w_1=\frac{n_1}{nm}\]
显然满足：
\[n_0+n_1=nm,\quad w_0+w_1=1\]
则二值化前的均值 $\mu$ 显然满足：
\[\mu=w_0\cdot\mu_0+w_1\cdot\mu_1\]
为了让方差最大化，设方差 $\sigma$ 为：
\[\sigma=w_0\cdot(\mu_0-\mu)^2+w_1\cdot(\mu_1-\mu)^2\]

联立解得：$\sigma=w_0\cdot w_1\cdot (\mu_0-\mu_1)^2$，因此，将所有 $\ge x$ 的点与 $< x$ 的点分别染色为两种灰度，即可实现灰度化。

具体到代码实现上，可以枚举 $x\in[0,255]$，然后分别计算 $\sigma$，将取得最大 $\sigma$ 的 $x$ 作为阈值即可。

考虑到在本题中，一般是从按的背景上分割出暗的物体(即数字)，所以将 $< x$ 的都染为黑色，$\ge x$ 的都染成白色。

上述代码涉及大量遍历图像的操作，将其用矩阵运算优化，能显著提升运算效率。时间复杂度为 $O(255nm)$，对较小的图像能以几乎一瞬间求出结果。

核心代码如下：
\begin{lstlisting}[language=python]
import numpy as np
def getThrestHold(img):
    n, m = img.shape
    mx, x = -1, 0  # mx是当前最大值,x是取得最值的阈值
    np.seterr(divide='ignore',invalid='ignore')#零除
    for i in range(0, 256):
        n0 = np.sum(img < i)
        n1 = n*m-n0
        w0 = n0/(n*m)
        w1 = 1-w0
        mu0 = np.sum(img[img < i])/n0
        mu1 = np.sum(img[img >= i])/n1
        g = w0*w1*(mu0-mu1)**2
        if g > mx:
            mx, x = g, i
    return x
\end{lstlisting}

这种算法的理论是很好的，但是在实践中我们发现了如下问题：如果要识别的图片除了 ISBN 区域外，还有较大片的封面内容，那么这些封面内容有可能要么颜色过浅、要么颜色过剩，他们都会干扰方差，从而使得二值化效果很差，不利于后续的图片切割等处理。

基于这个缺陷，我们在上文中最终替换了算法，最终版本如上文所示。改进后显著提升了准确率。

\subsubsection{图片分割}
最开始的思路是在二值化下先做形态学预处理再进行矩形识别。具体如下：

根据课件(第12章-形态学图像处理)可知，数学形态学图像处理的基本思想是：用具有一定形态的结构元素(如一定大小的矩形、圆或菱形等)探测目标图像，能达到图像分析与识别的目的。因此，考虑使用形态学方法进行处理并提取出有效的子图区域。

观察可知，ISBN 的有效区域总是一个白色的矩形为背景的。我们可以考虑找到这个矩形区域并将其提取出来。

根据课件内容可知，闭运算(先膨胀再腐蚀)能磨光物体内边界，开运算(先腐蚀再膨胀)能磨光图像外边界。

根据类似的经验，我们可以先膨胀图像，将条形码矩形的内部内容去掉，用背景色替代，再进行一次腐蚀去噪。

之后定义一个横向的长条矩形，如 $(n\times 1)$ 矩形进行膨胀；然后用 $(1\times m)$ 的纵向矩形进行腐蚀，去掉纵向的残留条形码等内容。考虑到膨胀与腐蚀操作的本质，我们认为 $n,m$ 的选取可以与具体图片的大小无关。这里使用的并非闭运算，因为前后不是同一个结构元素。根据经验，设 $n=20,m=15$。

在实践过程中，发现效果不理想，一个是膨胀会将背景中的干扰元素进行放大化，加剧其的干扰，二是腐蚀效果不佳，无法良好去噪。我们发现其更多时候甚至起到了负面的作用，即如果不进行形态学预处理，对矩形框的识别率反而更高。

因此，在最终实现中，我们没有采用形态学方法，而是采用了两次识别的方法。

\subsubsection{字符分割}
在初版设计中，我采用了如下的思路分割行：

数字区域的水平特征是，出现在条形码区域的附近，且边界是低频率的。那么我们可以先按水平特征截取出数字行，再进一步分析。在实现上，可以设一个低频阈值 $low$，如果某一行出现黑点个数 $\ge low$，就开始记为边界，直到下一次再出现 $< low$ 的行就设为另一边界，并把边界之间的行全部提取出来。根据肉眼观察和经验推理，不妨预设 $low=25\%max$，即最高频次的 $25\%$。

核心代码如下：
\begin{lstlisting}[language=python]
def getNumberLineRange(sumHori, low=0.25):
    lim = np.max(sumHori)*low  # 实际阈值
    left, right = -1, -1
    n = sumHori.shape[0]
    for i in range(n-1, -1, -1):
        if sumHori[i] >= lim and right == -1:
            right = i
        if sumHori[i] < lim and right != -1:
            left = i
            break
    return [max(0, left), max(0, right)]
\end{lstlisting}

该设计具有缺陷如下：

一、会被定价干扰。在ISBN里，定价附在矩形框内是很正常的，而且通常是在最下方。那么自底向上遍历，找到的行将会是定价这一行。(如测试集09)

二、无法解决残缺图像。如果拍照者只拍摄了上方的条形码，则自底向上找到的第一行是条形码。

三、基于最大值作阈值判断，稳定性不强。如果一张图片的边缘是全黑的，阈值会过高，导致判断失败。

四、虽然下面的数字行没有 ISBN 字符和横线，但是其与条形码过于接近，很容易被条形码干扰，特别是图片拍摄条件不良时，或者条形码与其间距太近时，又有轻微旋转干扰的话，可能很难分割出来。

基于这些缺陷，我们在上文中最终改进了算法。最终版本如上文所示。改进后显著提升了准确率。

\subsubsection{字符识别}
在初版设计中，我使用了方正舒体、宋体、清松手写体。如图所示：

\begin{figure}[H]
    \centering
    \includegraphics[height=90pt]{standard_fonts}
    \caption{标准字体}
\end{figure}

将其进行字符分割，得到标准模板。然而，其效果并不好，连最简单最规范的 ISBN 图片都无法识别。我们认为原因有两个：一个是这些字体并非是条形码常用字体，与实际环境的差异较大，不管是字形还是长宽比还是其他特征差异都较大；第二个是在预处理这些字体时，上下左右留出的空白空间较多，这导致做模板匹配时经常会失配。

基于这些缺陷，我们在上文中最终改进了算法。最终版本如上文所示。改进后显著提升了准确率。改进后显著提升了准确率。

\section{总结与体会}
\subsection{归纳和总结}
完成该项目是一个艰辛的过程。根据做项目过程的 git 版本记录\textit{(为了防止项目意外丢失，我使用了 git 进行备份工作)}可知，我从 2022 年 12 月 5 日开始做本项目，直到 12 月 10 日才完成全部工作，期间的每一天除了上课时间都在从早到晚做项目。如图所示：

\begin{figure}[H]
    \centering
    \includegraphics[height=90pt]{working_log}
    \caption{项目完成过程的不完整记录}
\end{figure}

在这期间遇到了许多的艰难险阻，也一一进行了解决。遇到的技术难点如下：

一、二值化的阈值难以选取，采用 Otsu 等自适应算法计算阈值的实践效果不理想。

解决办法：考虑到灰度取值很少，可以等间距枚举阈值，对不同阈值都计算一次 ISBN 取最优。这种思路虽然朴素但很有效，也证明了简单的办法未必就是坏办法。\textit{(事实上Otsu算法的实现也是枚举了 $255$ 次灰度)。}

二、将图片自动旋转到数字行水平时，因图片大小有差异，使用 Hough 算法直线检测时受长宽影响大。

解决办法：进行直线检测时快速枚举直线长度阈值。类比算法里的二分/倍增法，我创造性地采用了倍数缩减的思路，一开始先给定很大的阈值，然后不断乘以一个 $< 1$ 的系数让其成比例缩小，直到找到直线或小到一定程度后停止。这样一来时间复杂度不会特别高，二来健壮性良好，解决了尺寸差异问题。

三、去除封面背景，识别图片中的条形码矩形框时识别效果差。

解决办法：一开始是打算先二值化，然后用形态学办法膨胀腐蚀，之后再做处理。然而发现这么做效果太差。因此，后来经过尝试，转而采用了先高斯模糊平滑去噪，再然后用 Canny 算子提取图像边界，之后再检测边界中的所有矩形。然而效果还是不理想。于是，我创造性地采用了两次处理的办法，即先对彩色图像进行一次上述方法分割，如果分割不出来，再在上文给定的枚举的二值化阈值下做二值化，然后再次分割。实践表明效果可观。

四、模板匹配的准确率很低，对一些图片很难识别出字符。

解决办法：条形码的字体并非是固定一套的，因此我准备了两套不同的字体，这样适应性更加。此外，我还进行了一系列比较复杂的人工优化过程，包括预筛选、校验、利用统计规律等方法，提高识别的准确率，取得了较为良好的结果。

当然，遇到的问题不止这些，因篇幅有限不再一一赘述。

综合来说，本项目运用了多种不同的数字图像技术，包括灰度化、二值化、直线检测、平滑、边缘检测、矩形检测、旋转、缩放、归一化、字符元素分割、基于模板匹配的字符元素识别等。项目综合性较强，实现难度较高，且运用了较新的技术，对现有技术进行了改进(如倍增法和二次探测)。

因为在最终测试中程序表现良好，故该项目有应用到实践中的潜质。

\subsection{不足与改进建议}
该项目目前仍然存在一些瑕疵，下面扼要地提出主要的问题及其对应的参考改进措施。

一、程序执行效率偏低，运行时间略久。

改进建议：可以使用 C++ 语言重写项目。这是因为 C++ 代码比 Python 代码运行速度要明显快。且 C++ 也有 OpenCV，可以轻松迁移本项目的代码。

二、对复杂图像的条形码区域分割与字符识别准确率不理想。

改进建议：不妨采用机器学习办法进行条形码区域识别与字符匹配。可以训练一个神经网络，或调用预处理模型。在训练良好的情况下，AI 识别的准确率要比模板识别高很多。

三、枚举阈值进行二值化效率低。

改进建议：寻找一种更优的办法评判二值化的好坏。例如 Tenengrad 梯度方法可以用于评价图像清晰度。如果清晰度低，证明二值化效果差。可以枚举求出最清晰的阈值。比枚举 ISBN 识别的效率更高(显然求多次二值化快于识别一次 ISBN)。

\subsection{收获与体会}
完成本项目，让我深入掌握了数字图像处理基础的实践技术，深刻理解了原理并学会了如何实际进行操作。这些通用的技术具有很多应用场景，能让我在日后遇到计算机视觉问题时，能更快地上手去解决问题，为我打下了良好且扎实的基础。

此外，在本项目中我巩固了 Python 编程能力。这也是我首次使用 \LaTeX 编写正式的文档，让我提高了表达能力和技能。

在这次项目编写中，遇到重重困难。持续高强度的挑战性工作能磨练我的意志，锻炼我的思维，提高我的能力，使我更好地适应未来的 IT 行业相关工作。

\section{致谢}
首先感谢梁艳老师。老师详细的课程讲解让我掌握了数字图像处理的基本知识与技能，使我具备能力以完成本项目。

接着感谢黄一肯同学，他为我提供了一些测试用的图片，并在项目开发过程中给予了我一些指导性的建议。

最后感谢互联网上各大论坛上的文章作者，他们为我写项目时提供了一些参考性的原理介绍、代码片段、效果分析等帮助。

\section{参考文献}

%没弄明白thebibliography
% \begin{thebibliography}{99}
%     \bibitem[otsu] 1tsu 算法解析
% \end{thebibliography}

\textit{(注：红色的是超链接，点击可以跳转到原文。)}

\begin{enumerate}
    \item \href{https://blog.csdn.net/a15779627836/article/details/124151125}{Otsu 算法解析}
    \item \href{https://www.cnblogs.com/skyfsm/p/8029668.html}{数字分割}
    \item \href{https://blog.csdn.net/weixin_42272768/article/details/111244896}{Canny边缘检测}
    \item \href{https://blog.csdn.net/qq_30460949/article/details/90293147}{Hough变换详解1}
    \item \href{https://blog.csdn.net/qq_41112170/article/details/125729100}{Hough变换详解2}
    \item \href{https://blog.csdn.net/wyx100/article/details/80541726}{图片旋转}
    \item \href{https://blog.csdn.net/weixin_47365088/article/details/116566822}{提取特定图片区域}
    \item \href{https://blog.csdn.net/LPYchengxuyuan/article/details/122003702?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-122003702-blog-124125975.pc_relevant_aa&spm=1001.2101.3001.4242.1&utm_relevant_index=3}{形状识别}
    \item 边缘检测 Suzuki, S. and Abe, K., TopologicalStructural Analysis of Digitized Binary Images by Border Following.CVGIP 30 1, pp32-46 (1985)
    \item 数字图像处理基础课程的全部课件(梁艳老师)
\end{enumerate}

\section{附录}
\subsection{项目结构}

文件结构如下：
\begin{description}
    \item[codes\textbackslash] 全部代码源码
    \begin{description}
        \item[template\textbackslash] 模板匹配所用标准模板图片 
        \item[main.py] 图形化窗口和主接口调用(运行该文件即可)
        \item[toGrey.py] 实现灰度化
        \item[toBinary.py] 实现二值化
        \item[preRotate.py] 实现将图片自动到数字行水平
        \item[graphCut.py] 实现切割出图片的条形码区域
        \item[stringSplit.py] 实现字符分割
        \item[stringMatch.py] 实现字符匹配识别
        \item[autoMatch.py] 核心函数接口所在，实现ISBN的优化识别
    \end{description}
    \item[imgs\textbackslash] 存放测试集图片
    \item[latex\underline\ raw\textbackslash] 本文档的 \LaTeX 源码 
\end{description}

\subsection{主要函数接口}
按代码文件列出其主要接口与函数，给出对传入参数和返回值的描述：
\begin{description}
    \item[main.py] 无接口。直接运行该代码文件。
    \item[toGrey.py] 实现灰度化
    \begin{itemize}
        \item \verb|toGrey(img)| \\
        传入图片矩阵，将其灰度化并返回二维矩阵
    \end{itemize}
    \item[toBinary.py] 实现二值化
    \begin{itemize}
        \item \verb|toBinary(img, x=200, ltx=0, gex=255)| \\
        传入灰度图img和阈值x,将其二值化并返回\\
        规定 $< x$ 的染成白色(ltx), $\ge x$ 的染成灰色(gex)
        \item \verb|getBinary(img0, x=200, ltx=0, gex=255)| \\
        先灰度化，再二值化，然后返回结果
    \end{itemize}
    \item[preRotate.py] 实现将图片自动到数字行水平
    \begin{itemize}
        \item \verb|getLines(img)| \\
        传入二值化图像,输出其倍增法所有检测出来的直线(极坐标直线组)
        \item \verb|getMidAngle(lines)| \\
        给定极坐标直线组,返回位于中位数斜角(角度制)
        \item \verb|rotateImg(img, ang)| \\
        以中心旋转图像,顺时针转动 ang 角度并返回(白色填充)
        \item \verb|autoRotateC(img)| \\
        以彩色图像为输入，输出自动旋转后的图像
    \end{itemize}
    \item[graphCut.py] 实现切割出图片的条形码区域
    \begin{itemize}
        \item \verb|getMainRectangle(img)| \\
        传入任意图像,返回其出现的最大矩形区域
        \item \verb|cutImage(img)| \\
        传入任意图像，找到最大矩形区域子图并返回\\
        如果找不到就返回原图
        \item \verb|autoCut(img0, thr)| \\
        传入彩色图像，两次匹配找到最大矩形区域子图\\
        返回结果是二值化后的子图
    \end{itemize}
    \item[stringSplit.py] 实现字符分割
    \begin{itemize}
        \item \verb|getHoriAndVertSum(img)| \\
        输入二值化图像,依次返回其行列黑色点数和的向量
        \item \verb|getRanges(sums, low=0.32)| \\
        输入向量,返回所有值 $\ge low \cdot$均值的连续峰段
        \item \verb|getNumberLineRange(sums, low=0.35)| \\
        输入向量,返回一个数字行的下标范围 $[l,r]$
        \item \verb|splitByVerts(img, lr)| \\
        输入图片和峰段,返回切割后的全部子图
        \item \verb|filtRanges(img, arr)| \\
        输入区间列表,返回经过初步筛选后的有效区间列表
        \item \verb|splitNumbers(img)| \\
        输入一张二值化图像，返回其分割出来的字符子图列表
        \item \verb|splitNumbers(img)| \\
        输入一张二值化图像，返回其分割出来的字符子图列表
        \item \verb|plotSumAnalyse(img0, draw2Hori=True)| \\
        绘制彩色图像的水平垂直频次分析
        \item \verb|plotSplit(img0)| \\
        绘图输出数字行和分割字符
        \item \verb|plotNumberLineAnalyse(img0)| \\
        绘图只输出数字行及其统计特征
    \end{itemize}
    \item[stringMatch.py] 实现字符匹配识别
    \begin{itemize}
        \item \verb|loadTemplates(path='templates')| \\
        从文件夹路径返回标准字符模板(经过二值化)
        \item \verb|compare(target, std)| \\
        比较 $target$ 与模板图像 $std$ 的相似性并返回
        \item \verb|getNumber(src)| \\
        将一张图片与全体模板比较，取最大相似的字符作结果
        \item \verb|getMatch(img)| \\
        给定二值化图像，输出识别结果数组
    \end{itemize}
    \item[autoMatch.py] 核心函数接口所在，实现ISBN的优化识别
    \begin{itemize}
        \item \verb|reshape(img, mw=1000, mh=1000)| \\
        给定图片,等比例裁剪使长宽不超 $mw,mh$
        \item \verb|preDeal(img0)| \\
        给定一张图片,将其裁剪大小和自动旋转
        \item \verb|filtRes(m)| \\
        输入匹配结果，对结果进行筛除和修正并返回
        \item \verb|getChecksum(m)| \\
        输入ISBN码序列,返回校验码
        \item \verb|checkISBN(m)| \\
        输入初筛后的校验码序列,校验它是否正确
        \item \verb|adjudgeByChecksum(m)| \\
        给定ISBN码序列,若不合校验码将其根据校验码校正并返回
        \item \verb|betterMatch(m1, m2)| \\
        给定两个匹配结果，选择最优的
        \item \verb|matchFlip(img)| \\
        给定一张图片,将其正反都匹配一次取最优返回
        \item \verb|iterMatch(img0)| \\
        给定一张图片,枚举二值化阈值取最好结果\\
        输出其ISBN字符串结果\textbf{(本项目核心函数接口)}
    \end{itemize}
\end{description}

\subsection{完整代码}
\subsubsection{main.py}
\lstinputlisting[language=python,breaklines]{../codes/main.py}

\subsubsection{toGrey.py}
\lstinputlisting[language=python,breaklines]{../codes/toGrey.py}

\subsubsection{toBinary.py}
\lstinputlisting[language=python,breaklines]{../codes/toBinary.py}

\subsubsection{preRotate.py}
\lstinputlisting[language=python,breaklines]{../codes/preRotate.py}

\subsubsection{graphCut.py}
\lstinputlisting[language=python,breaklines]{../codes/graphCut.py}

\subsubsection{stringSplit.py}
\lstinputlisting[language=python,breaklines]{../codes/stringSplit.py}

\subsubsection{stringMatch.py}
\lstinputlisting[language=python,breaklines]{../codes/stringMatch.py}

\subsubsection{autoMatch.py}
\lstinputlisting[language=python,breaklines]{../codes/autoMatch.py}

\end{document}